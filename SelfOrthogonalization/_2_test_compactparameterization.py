""" Test out circuit to span compact basis.

To illustrate our self-orthogonalizing circuitry,
    we need a circuit construction which can span the full Hilbert space
    but can also be conveniently restricted to cut out individual basis states.

Our best idea right now is one we developed aeons ago,
    (probably related to the "Variational Hamiltonian Ansatz" maybe?)

    Î©[l] = exp[-ğ‘–Ï€ (T[l]+T[l]â€ )/2]

    T[l] = âˆ‘ Ï•[i] aâ€ [i] a[l]

Constructing each term aâ€ a in the compact basis is straightforward:

    aâ€ [i] a[l] = |iâŸ©âŸ¨l| = |i[0]âŸ©âŸ¨l[0]| âŠ— ... âŠ— |i[n]âŸ©âŸ¨l[n]|

    |0âŸ©âŸ¨0| = (I + Z) / 2
    |0âŸ©âŸ¨1| = (X + ğ‘–Y) / 2
    |1âŸ©âŸ¨0| = (X - ğ‘–Y) / 2
    |1âŸ©âŸ¨1| = (I - Z) / 2

We have confirmed this circuit produces the desired result,
    provided the phase on first element of Ï• is 0.

Now we've developed a parameterization for Ï• which feels right:

    |Ï•âŸ© = r0 |0âŸ© + r1 exp(2Ï€ğ‘– Î±1) |1âŸ© + ... rn exp(2Ï€ğ‘– Î±n) |nâŸ©

        r0 = sin(Ï€/2 t0)
        r1 = cos(Ï€/2 t0) * sin(Ï€/2 t1)
        ...
        r[n-1] = cos(Ï€/2 t0) ... cos(Ï€/2 t[n-2]) sin(Ï€/2 t[n-1])
        r[n]   = cos(Ï€/2 t0) ... cos(Ï€/2 t[n-2]) cos(Ï€/2 t[n-1])

    Thus both t and Î± are taken from [0,1],
        and we can eliminate |m<lâŸ© by setting t[m<l] = Î±[mâ‰¤l] = 0.

So we just want to make sure that, for any Ï•,
    we can reliably find parameters t and Î± which produce that Ï•.
    Î± is trivially scaled by Î³, the phase angle for each element of Ï•.
    A little harder to show, but solving for t yields only tâˆˆ[0,1].

But I'd like to convince myself that these are, like, good parameters.
    If we randomly generate Ï•, we should see a random distribution of Î±, t.
    It NEEDS to fill the whole space. Ideally it does so uniformally.

So we should generate lots of Ï• (standardized), calculate Î± and t,
    then histogram each variable. 6 plots; should all look uniform.
    Next plot each variable against the other (6c2)=15 plots.
    They should all appear uncorrelated.

We can also generate lots of t, Î± uniform,
    and check that fidelities distribute suitably random.

"""

import numpy as np
np.set_printoptions(3, suppress=True)
from numpy import pi as Ï€

import scipy.stats

def statevector(t, Î±):
    """ Construct statevector from parameterization. """
    N = 1 + len(t)                              # NUMBER OF COMPLEX VALUES

    # FILL IN MODULI
    r = np.empty(N)
    Î _cos = 1
    for n in range(N-1):
        r[n]   = np.sin(Ï€/2 * t[n]) * Î _cos
        Î _cos *= np.cos(Ï€/2 * t[n])
    r[N-1] = Î _cos

    # FILL IN PHASE ANGLES
    Î³ = np.zeros(N)
    Î³[1:] = 2*Ï€ * Î±

    # CONSTRUCT STATEVECTOR
    return r * np.exp(1j*Î³)

def parameters(Ï•):
    """ Construct parameters from statevector. """
    N = len(Ï•)

    # POLAR PARAMETERIZATION
    r = np.abs(Ï•)
    Î³ = np.angle(Ï•)

    # CHECK THAT Ï• IS NORMALIZED
    if abs(Î³[0]) > 4 * np.finfo(float).eps:
        raise ValueError(f"|Î³[0]|={abs(Î³[0])} > 4*{np.finfo(float).eps}")

    # FILL IN t
    t = np.empty(N-1)
    Î _cos = 1
    for n in range(N-1):
        t[n] = 2/Ï€ * np.arcsin( r[n] / Î _cos )
        Î _cos *= np.cos(Ï€/2 * t[n])

    # FILL IN Î±
    Î± = Î³[1:] / (2*Ï€)

    return t, Î±

def standardize(Ï•):
    """ Factor out the angle of element 0. """
    Î³ = np.angle(Ï•[0])
    return Ï• * np.exp(-1j*Î³)

def fidelity(Ï•,Ïˆ):
    """ Calculate fidelity âŸ¨Ï•|ÏˆâŸ©âŸ¨Ïˆ|Ï•âŸ© """
    return abs(np.vdot(Ï•,Ïˆ))**2

def random_statevector(N, seed):
    """ Construct a statevector, randomized according to the seed. """
    rng = np.random.default_rng(seed)
    return scipy.stats.unitary_group.rvs(N, random_state=rng)[:,0]

def random_parameters(N, seed):
    """ Generate N+2 random numbers in [0, 1), and split into two lists. """
    rng = np.random.default_rng(seed)
    rnd = rng.random(N+2)
    return rnd[:(N+2)//2], rnd[(N+2)//2:]


##############################################################################
#           GET A FEEL FOR HOW FIDELITIES OF RANDOM STATEVECTORS LOOK
import matplotlib.pyplot as plt

T = 1000
N = 4
Ï•s = [standardize(random_statevector(N,i)) for i in range(T)]

F_matrix = np.empty((T,T))
for i in range(T):
    for j in range(T):
        F_matrix[i,j] = fidelity(Ï•s[i], Ï•s[j])

plt.matshow(F_matrix)

_ = plt.hist(F_matrix.flatten(), 50)

##############################################################################
#           SEE IF IT STILL LOOKS RIGHT FROM RANDOM PARAMETERS
import matplotlib.pyplot as plt

T = 1000
N = 4
Ï•s = [statevector(*random_parameters(N,i)) for i in range(T)]

F_matrix = np.empty((T,T))
for i in range(T):
    for j in range(T):
        F_matrix[i,j] = fidelity(Ï•s[i], Ï•s[j])

plt.matshow(F_matrix)

_ = plt.hist(F_matrix.flatten(), 50)

""" No, it does not look right.

This does not strictly mean it's BAD, but
1) it must be born in mind when discussing optimization.
2) a transformation to make it uniform would be good.
3) we need another check to validate we're spanning the whole space properly.

            ...eh, oh well.

"""

##############################################################################
#               CHECK RANDOMNESS OF PARAMETERIZATION
import matplotlib.pyplot as plt

T = 10000
N = 4
params = np.empty((T,N+2))
for i in range(T):
    Ï• = standardize(random_statevector(N,i))
    t, Î± = parameters(Ï•)
    params[i] = np.concatenate((t,Î±))

# PLOT HISTOGRAMS OF EACH PARAMETER
for p in range(N+2):
    plt.hist(params[:,p], 50)
    plt.title(f"p={p}")
    plt.figure()

# PLOT SCATTER PLOTS CORRELATING EACH PARAMETER
for p in range(N+2):
    for q in range(p):
        plt.plot(params[:,p], params[:,q], '.k')
        plt.title(f"(p,q)=({p},{q})")
        plt.figure()

""" t is clearly not exactly uniform.

However I do judge it good enough - onward!

"""
